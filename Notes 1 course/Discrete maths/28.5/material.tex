\section{Приближённые алгоритмы}

\subsection{Муравьиная колония}

Продемонстрируем на задаче коммивояжёра: \\
На входе $ n $ городов \\
Определяем $ m $ -- количество муравьёв \\
Каждый муравей будет строить свой маршрут, и будет оставлять в каждом городе какое-то количество ферромона. Остальные муравьи будут при выборе маршрута это учитывать \\
Есть несколько способ выбрать начальные города:
\begin{itemize}
	\item ``Рассадить'' всех по разным городам
    \item ``Посадить'' всех в один город
    \item ``Рассадить'' группами
\end{itemize}
Так что, считаем что изначально каждый муравей находится в каком-то городе \\
$ d(i, j) $ -- длина ребра $ i, j $ \\
$ N_i^k $ -- в $ i $-м городе, $ k $ -- номер муравья -- непосещённые города
$$ \eta(i, j) \define \frac1{d(i, j)} $$
$ \tau(i, j) $ -- количество ферромона на дуге $ i, j $ \\
$ p(i, j) $ -- вероятность перехода из $ i $ в $ j $ \\
Когда алгоритм закончится, получим $ m $ маршрутов, и выберем из них кратчайший \\
Естетственно, этот процесс повторяется несколько раз (возможно, с разными ``рассадками'' муравьёв) \\
Запишем формулу для вероятности:
$$ p(i, j) = \frac{[\tau(i, j)]^\alpha \cdot [\eta(i, j)]^\beta}{\sum_{l \in N_i^k} [\tau(i, l)]^\alpha \cdot [\eta(i, l)]^\beta} $$
После этого, применяем схему Уолкера и выбираем город, куда дальше идти
\begin{itemize}
	\item $ \alpha, \beta $ -- некоторые параметры, которые вводятся заранее (чаще всего, определяются экспериментально)
    \item $ \tau(i, j) $ -- количество ферромона
    \item $ \eta(i, j) $ -- функция ``качества'' ребра (зависит от его длины)
    \item В значенателе -- все непосещённые варианты
\end{itemize}

\begin{note}
	На первом шаге, ферромона везде одинаково, а значит, вероятность определяется только длиной дуги
\end{note}

\begin{undefthm}{Как меняется ферромон?}
    $$ \tau(i, j) = \rho \cdot \tau(i, j) + \sum_{k = 1}^m \vtri \tau(i, j) $$
    $$ \vtri \tau(i, j) =
    \begin{cases}
        \faktor1{L_k}, \quad (i, j) \in P_{L_k} \\
        0
    \end{cases} $$
\end{undefthm}

\begin{itemize}
	\item $ \rho $ -- некий понижающий коэффициент, определяется заранее, $ \rho \in (0, 1] $
    \item $ L_k $ -- длина маршрута, уже пройденного $ k $-м муравьём
    \item $ P_{L_k} $ -- путь, уже пройденный $ k $-м муравьём
\end{itemize}

\begin{note}
	Ферромон со временем ``испаряется'': \\
    Если $ k $-й муравей не посетил ребро $ i, j $, то $ \tau(i, j) = \rho \cdot \tau(i, j) $
\end{note}

Пять пунктов, которые нужно придумать, чтобы применить муравьиный алгоритм:
\begin{enumerate}
	\item $ \eta(i, j) $ -- функция ``качества''
    \item Определение ферромона
    \item Правило обновления ферромона
    \item Функция, определяющая качество всего решения (фитнес-функция) \\
    У нас это была длина маршрута
    \item Как муравьи строят решение и определяют, что решение построено?
\end{enumerate}

\subsection{Локальный поиск}

$ x_0 $ -- начальное решение \\
$ x \in U(x_0) $ -- окрестность решения
$ f(x) $ -- целевая функция
\begin{itemize}
	\item Если $ f(x) < f(x_0) $, то $ x_0 \define x $ \\
    Переходим в начало
\end{itemize}

\subsection{Поиск с запретами}

Возьмём самый простой вариант окрестности для задачи коммивояжёра: \\
Берём два случайных города из маршрута и меняем их местами \\
В таком случае можно зациклиться -- поменять их обратно \\
Вводим список запретов. Его длина задаётся заранее (не очень много) \\
Кждое принятое решение записывается в этот список \\
Если место кончилось -- выталькивается первая запись \\
Если на следующем шаге мы выбрали действие, которое есть в списке, то его не делаем (выбираем другое)

\subsection{Имитация отжига}

$ S_i $ -- состояние (само решение) \\
$ T_i $ -- температура \\
$ E $ -- энергия \\
Нужно определить $ S_0 $ -- начльное решение и $ T_{max}, T_{min} $ \\
$ f $ -- функция изменения состояния

\begin{algorithm}
    \hfill
    \begin{enumerate}
        \item Вычислить $ S_{new} = f(S_{i - 1}) $
        \item
        \begin{itemize}
            \item Если $ S_{new} $ лучше, то переходим в него
            \item Если хуже, то переходим с вероятностью $ P(\vtri E, T) $
        \end{itemize}
        \item Уменьшаем $ T $
    \end{enumerate}
\end{algorithm}

\begin{algorithm2e}
    i \Define 1 \\
    $ T_0 $ \Define $ T_{max} $ \\
    $ S_{best} $ \Define $ S_0 $ \\
    \While{$ T_i > T_{min} $}{
        $ S_{new} $ \Define $ f(S_{i - 1}) \quad $ \tcp{метод перехода $ S_{i + 1} \to S_{new} $}
        $ \vtri E = E(S_{new}) - E(S_{i - 1}) $ \\
        \eIf{$ p(\vtri E) \ge $ random(0, 1)}{
            $ S_i $ \Define $ S_{new} $
        }{
            $ S_i $ \Define $ S_{i - 1} $
        }
        \If{$ E(S_i) < E(S_{best}) $}{
            $ S_{best} $ \Define $ S_i $ \\
            ++i
        }
        $ T_{i + 1} $ \Define $ f(T_i) $
    }
\end{algorithm2e}

\subsection{Иммунный алгоритм}

\begin{enumerate}
	\item Начальная популяция
    \item Клонирование
    \item Мутации
    \item Афинность
\end{enumerate}

Количество решений определяется качеством решения \\
Для афинности есть формула:
$$ A(k) = \frac{LB}{1 + M(k) - LB} $$
\begin{itemize}
	\item LB -- Lower Bound -- нижняя граница решения
    \item $ M(k) $ -- качество решения
\end{itemize}

Из клонов выбираем лучшего. Если он лучше отца, помещаем его в популяцию
